{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spesifikasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MP = 5\n",
    "\n",
    "Electrolytic Capacitor: 25 V Nippon KZE series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Capacitor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "47\t100\t220\t330\t470\t680\t820\t1000\t1500\t1800\t2200\t2700"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series combinations saved to series_combinations.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from itertools import combinations\n",
    "\n",
    "def read_capacitor_values_from_csv(csv_filename):\n",
    "    capacitors = []\n",
    "\n",
    "    with open(csv_filename, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            capacitors.append({\n",
    "                'value': float(row['Cap(uF)']),\n",
    "                'volume': float(row['Volume(mm^2)'])\n",
    "            })\n",
    "\n",
    "    return capacitors\n",
    "\n",
    "def calculate_series_combinations(capacitors, max_parallel=5, max_capacitance=1000):\n",
    "    series_combinations = []\n",
    "\n",
    "    for r in range(1, min(max_parallel + 1, len(capacitors) + 1)):\n",
    "        # Generate all possible combinations of r capacitors\n",
    "        for combination in combinations(capacitors, r):\n",
    "            # Calculate equivalent capacitance for the series combination\n",
    "            equivalent_capacitance = sum(1 / cap['value'] for cap in combination) ** -1\n",
    "\n",
    "            # Check if the equivalent capacitance is below the threshold\n",
    "            if equivalent_capacitance > max_capacitance:\n",
    "                continue  # Discard this combination\n",
    "\n",
    "            # Calculate total volume for the series combination\n",
    "            total_volume = sum(cap['volume'] for cap in combination)\n",
    "\n",
    "            # Append the combination, equivalent capacitance, and total volume to the list\n",
    "            series_combinations.append({\n",
    "                'combination': [cap['value'] for cap in combination],\n",
    "                'equivalent_capacitance': equivalent_capacitance,\n",
    "                'total_volume': total_volume\n",
    "            })\n",
    "\n",
    "    return series_combinations\n",
    "\n",
    "def save_to_csv(series_combinations, csv_filename):\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['Combination', 'Cap(uF)', 'Total_Volume(mm^2)']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for combination in series_combinations:\n",
    "            # Round capacitance and total volume to 9 decimal places\n",
    "            capacitance_rounded = round(combination['equivalent_capacitance'], 9)\n",
    "            total_volume_rounded = round(combination['total_volume'], 9)\n",
    "\n",
    "            writer.writerow({\n",
    "                'Combination': \"series:\" + str(combination['combination']),\n",
    "                'Cap(uF)': capacitance_rounded,\n",
    "                'Total_Volume(mm^2)': total_volume_rounded\n",
    "            })\n",
    "\n",
    "# Specify the CSV file containing capacitor values and volumes\n",
    "capacitor_csv_filename = r'E:\\ai-power-converter-1\\new\\cap.csv'\n",
    "\n",
    "# Read capacitor values and volumes from CSV\n",
    "capacitors = read_capacitor_values_from_csv(capacitor_csv_filename)\n",
    "\n",
    "# Maximum parallel connections (MP)\n",
    "max_parallel = 5\n",
    "\n",
    "# Maximum capacitance threshold\n",
    "max_capacitance = 1000\n",
    "\n",
    "# Calculate series combinations\n",
    "series_combinations = calculate_series_combinations(capacitors, max_parallel, max_capacitance)\n",
    "\n",
    "# Save to CSV file\n",
    "csv_filename = 'series_combinations.csv'\n",
    "save_to_csv(series_combinations, csv_filename)\n",
    "print(f\"Series combinations saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parallel combinations saved to parallel_combinations.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from itertools import combinations\n",
    "\n",
    "def read_capacitor_values_from_csv(csv_filename):\n",
    "    capacitors = []\n",
    "    with open(csv_filename, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            capacitor = {\n",
    "                'value': float(row['Cap(uF)']),\n",
    "                'volume': float(row['Volume(mm^2)'])\n",
    "            }\n",
    "            capacitors.append(capacitor)\n",
    "    return capacitors\n",
    "\n",
    "def calculate_parallel_combinations(capacitors, max_parallel=5, max_equivalent_capacitance=1000):\n",
    "    parallel_combinations = []\n",
    "    for r in range(1, min(max_parallel + 1, len(capacitors) + 1)):\n",
    "        # Generate all possible combinations of r capacitors\n",
    "        for combination in combinations(capacitors, r):\n",
    "            # Calculate equivalent capacitance for the parallel combination\n",
    "            equivalent_capacitance = sum(capacitor['value'] for capacitor in combination)\n",
    "            # Calculate total volume for the parallel combination\n",
    "            total_volume = sum(capacitor['volume'] for capacitor in combination)\n",
    "            # Check if the equivalent capacitance is below the threshold\n",
    "            if equivalent_capacitance <= max_equivalent_capacitance:\n",
    "                # Append the combination, equivalent capacitance, and total volume to the list\n",
    "                parallel_combinations.append({\n",
    "                    'combination': [capacitor['value'] for capacitor in combination],\n",
    "                    'equivalent_capacitance': equivalent_capacitance,\n",
    "                    'total_volume': total_volume\n",
    "                })\n",
    "    return parallel_combinations\n",
    "\n",
    "def save_to_csv(parallel_combinations, csv_filename):\n",
    "    with open(csv_filename, 'w', newline='',     encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['Combination', 'Cap(uF)', 'Total_Volume(mm^2)']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for combination in parallel_combinations:\n",
    "            # Round capacitance and total volume to 9 decimal places\n",
    "            capacitance_rounded = round(combination['equivalent_capacitance'], 9)\n",
    "            total_volume_rounded = round(combination['total_volume'], 9)\n",
    "            writer.writerow({\n",
    "                'Combination': \"parallel:\" + str(combination['combination']),\n",
    "                'Cap(uF)': capacitance_rounded,\n",
    "                'Total_Volume(mm^2)': total_volume_rounded\n",
    "            })\n",
    "\n",
    "# Specify the CSV file containing capacitor values and volumes\n",
    "capacitor_csv_filename = r'E:\\ai-power-converter-1\\new\\cap.csv'\n",
    "\n",
    "# Read capacitor values and volumes from CSV\n",
    "capacitors = read_capacitor_values_from_csv(capacitor_csv_filename)\n",
    "\n",
    "# Maximum parallel connections\n",
    "max_parallel = 5\n",
    "\n",
    "# Maximum equivalent capacitance threshold (in farads)\n",
    "max_equivalent_capacitance = 1000\n",
    "\n",
    "# Calculate parallel combinations\n",
    "parallel_combinations = calculate_parallel_combinations(capacitors, max_parallel, max_equivalent_capacitance)\n",
    "\n",
    "# Save to CSV file\n",
    "csv_filename = 'parallel_combinations.csv'\n",
    "save_to_csv(parallel_combinations, csv_filename)\n",
    "print(f\"Parallel combinations saved to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data merged into merged_combinations.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from itertools import combinations\n",
    "\n",
    "def read_csv(file_path):\n",
    "    data = []\n",
    "    with open(file_path, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        headers = next(reader)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    return headers, data\n",
    "\n",
    "def write_csv(file_path, headers, data):\n",
    "    with open(file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(headers)\n",
    "        writer.writerows(data)\n",
    "\n",
    "def read_capacitor_values_from_csv(csv_filename):\n",
    "    capacitors = []\n",
    "    with open(csv_filename, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            capacitors.append({\n",
    "                'value': float(row['Cap(uF)']),\n",
    "                'volume': float(row['Volume(mm^2)'])\n",
    "            })\n",
    "    return capacitors\n",
    "\n",
    "def calculate_parallel_combinations(capacitors, max_parallel=5, max_capacitance=1000):\n",
    "    parallel_combinations = []\n",
    "    for r in range(1, min(max_parallel + 1, len(capacitors) + 1)):\n",
    "        for combination in combinations(capacitors, r):\n",
    "            equivalent_capacitance = sum(cap['value'] for cap in combination)\n",
    "            if equivalent_capacitance > max_capacitance:\n",
    "                continue  # Discard this combination\n",
    "            total_volume = sum(cap['volume'] for cap in combination)\n",
    "            parallel_combinations.append({\n",
    "                'combination': \" || \".join(map(str, [cap['value'] for cap in combination])),\n",
    "                'equivalent_capacitance': equivalent_capacitance,\n",
    "                'total_volume': total_volume\n",
    "            })\n",
    "    return parallel_combinations\n",
    "\n",
    "def calculate_series_combinations(capacitors, max_series=5, max_capacitance=1000):\n",
    "    series_combinations = []\n",
    "    for r in range(1, min(max_series + 1, len(capacitors) + 1)):\n",
    "        for combination in combinations(capacitors, r):\n",
    "            equivalent_capacitance = sum(1 / cap['value'] for cap in combination) ** -1\n",
    "            if equivalent_capacitance > max_capacitance:\n",
    "                continue  # Discard this combination\n",
    "            total_volume = sum(cap['volume'] for cap in combination)\n",
    "            series_combinations.append({\n",
    "                'combination': \" + \".join(map(str, [cap['value'] for cap in combination])),\n",
    "                'equivalent_capacitance': equivalent_capacitance,\n",
    "                'total_volume': total_volume\n",
    "            })\n",
    "    return series_combinations\n",
    "\n",
    "def combine_files(file1_path, file2_path, output_file_path, max_capacitance=1000):\n",
    "    headers_file1, data_file1 = read_csv(file1_path)\n",
    "    headers_file2, data_file2 = read_csv(file2_path)\n",
    "\n",
    "    if headers_file1 != headers_file2:\n",
    "        raise ValueError(\"Headers in the two files are not the same.\")\n",
    "\n",
    "    combined_data = []\n",
    "\n",
    "    for row_file1 in data_file1:\n",
    "        for row_file2 in data_file2:\n",
    "            combination = f\"{row_file1[0]} and {row_file2[0]}\"\n",
    "            capacitance_sum = round(float(row_file1[1]) + float(row_file2[1]), 9)\n",
    "            total_volume_sum = round(float(row_file1[2]) + float(row_file2[2]), 9)\n",
    "\n",
    "            if capacitance_sum <= max_capacitance:\n",
    "                combined_data.append([combination, capacitance_sum, total_volume_sum])\n",
    "\n",
    "    write_csv(output_file_path, ['Combination', 'Cap(uF)', 'Total_Volume(mm^2)'], combined_data)\n",
    "\n",
    "def merge_all_files(output_file_path, *file_paths):\n",
    "    all_data = []\n",
    "    for file_path in file_paths:\n",
    "        headers, data = read_csv(file_path)\n",
    "        if not all_data:\n",
    "            all_data.append(headers)  # Add headers only once\n",
    "        all_data.extend(data)\n",
    "    \n",
    "    write_csv(output_file_path, all_data[0], all_data[1:])\n",
    "    print(f\"All data merged into {output_file_path}\")\n",
    "\n",
    "# Main code to generate parallel and series combinations and save to CSV\n",
    "\n",
    "capacitor_csv_filename = r'E:\\ai-power-converter-1\\new\\cap.csv'\n",
    "output_parallel_csv = 'parallel_combinations.csv'\n",
    "output_series_csv = 'series_combinations.csv'\n",
    "combined_output_csv = 'combination_result.csv'\n",
    "final_merged_csv = 'merged_combinations.csv'\n",
    "\n",
    "# Read capacitor values and volumes from CSV\n",
    "capacitors = read_capacitor_values_from_csv(capacitor_csv_filename)\n",
    "\n",
    "# Calculate parallel combinations\n",
    "parallel_combinations = calculate_parallel_combinations(capacitors, max_capacitance=1000)\n",
    "\n",
    "# Save parallel combinations to CSV\n",
    "write_csv(output_parallel_csv, ['Combination', 'Cap(uF)', 'Total_Volume(mm^2)'], [\n",
    "    [comb['combination'], comb['equivalent_capacitance'], comb['total_volume']]\n",
    "    for comb in parallel_combinations\n",
    "])\n",
    "\n",
    "# Calculate series combinations\n",
    "series_combinations = calculate_series_combinations(capacitors, max_capacitance=1000)\n",
    "\n",
    "# Save series combinations to CSV\n",
    "write_csv(output_series_csv, ['Combination', 'Cap(uF)', 'Total_Volume(mm^2)'], [\n",
    "    [comb['combination'], comb['equivalent_capacitance'], comb['total_volume']]\n",
    "    for comb in series_combinations\n",
    "])\n",
    "\n",
    "# Combine both parallel and series combinations\n",
    "combine_files(output_parallel_csv, output_series_csv, combined_output_csv)\n",
    "\n",
    "# Merge all three CSV files into one\n",
    "merge_all_files(final_merged_csv, output_parallel_csv, output_series_csv, combined_output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def read_csv(file_path):\n",
    "    data = []\n",
    "    with open(file_path, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        headers = next(reader)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    return headers, data\n",
    "\n",
    "def write_csv(file_path, headers, data):\n",
    "    with open(file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(headers)\n",
    "        writer.writerows(data)\n",
    "\n",
    "def combine_files(file1_path, file2_path, file3_path, output_file_path):\n",
    "    headers_file1, data_file1 = read_csv(file1_path)\n",
    "    headers_file2, data_file2 = read_csv(file2_path)\n",
    "    headers_file3, data_file3 = read_csv(file3_path)\n",
    "\n",
    "    # Ensure headers are the same for all three files\n",
    "    if headers_file1 != headers_file2 or headers_file2 != headers_file3:\n",
    "        raise ValueError(\"Headers in the three files are not the same.\")\n",
    "\n",
    "    # Combine data from all three files\n",
    "    combined_data = data_file1 + data_file2 + data_file3\n",
    "\n",
    "    # Write the combined data to a new CSV file\n",
    "    write_csv(output_file_path, headers_file1, combined_data)\n",
    "\n",
    "# Example usage\n",
    "combine_files('parallel_combinations.csv', 'series_combinations.csv', 'combination_result.csv', 'final_combined_result_val.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove multiple values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def read_csv(file_path):\n",
    "    data = []\n",
    "    with open(file_path, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        headers = next(reader)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    return headers, data\n",
    "\n",
    "def write_csv(file_path, headers, data):\n",
    "    with open(file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(headers)\n",
    "        writer.writerows(data)\n",
    "\n",
    "def combine_files(file1_path, file2_path, file3_path, output_file_path):\n",
    "    headers_file1, data_file1 = read_csv(file1_path)\n",
    "    headers_file2, data_file2 = read_csv(file2_path)\n",
    "    headers_file3, data_file3 = read_csv(file3_path)\n",
    "\n",
    "    # Ensure headers are the same for all three files\n",
    "    if headers_file1 != headers_file2 or headers_file2 != headers_file3:\n",
    "        raise ValueError(\"Headers in the three files are not the same.\")\n",
    "\n",
    "    # Combine data from all three files\n",
    "    combined_data = data_file1 + data_file2 + data_file3\n",
    "\n",
    "    # Remove duplicate rows based on Capacitance and Total Volume\n",
    "    unique_data = []\n",
    "    unique_keys = set()\n",
    "    for row in combined_data:\n",
    "        key = (row[1], row[2])  # Assuming Capacitance is at index 1, Total Volume is at index 2\n",
    "        if key not in unique_keys:\n",
    "            unique_data.append(row)\n",
    "            unique_keys.add(key)\n",
    "\n",
    "    # Write the combined data to a new CSV file\n",
    "    write_csv(output_file_path, headers_file1, unique_data)\n",
    "\n",
    "# Example usage\n",
    "combine_files('parallel_combinations.csv', 'series_combinations.csv', 'combination_result.csv', 'final_combined_result_dif_val.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisi MP = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data merged into merged_combinations_revisi.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from itertools import combinations\n",
    "\n",
    "def read_csv(file_path):\n",
    "    data = []\n",
    "    with open(file_path, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        headers = next(reader)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    return headers, data\n",
    "\n",
    "def write_csv(file_path, headers, data):\n",
    "    with open(file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(headers)\n",
    "        writer.writerows(data)\n",
    "\n",
    "def read_capacitor_values_from_csv(csv_filename):\n",
    "    capacitors = []\n",
    "    with open(csv_filename, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            capacitors.append({\n",
    "                'value': float(row['Cap(uF)']),\n",
    "                'volume': float(row['Volume(mm^2)'])\n",
    "            })\n",
    "    return capacitors\n",
    "\n",
    "def calculate_parallel_combinations(capacitors, max_parallel=5, max_capacitance=1000):\n",
    "    parallel_combinations = []\n",
    "    for r in range(1, min(max_parallel + 1, len(capacitors) + 1)):\n",
    "        for combination in combinations(capacitors, r):\n",
    "            equivalent_capacitance = sum(cap['value'] for cap in combination)\n",
    "            if equivalent_capacitance > max_capacitance:\n",
    "                continue  # Discard this combination\n",
    "            total_volume = sum(cap['volume'] for cap in combination)\n",
    "            parallel_combinations.append({\n",
    "                'combination': \" || \".join(map(str, [cap['value'] for cap in combination])),\n",
    "                'equivalent_capacitance': equivalent_capacitance,\n",
    "                'total_volume': total_volume,\n",
    "                'count': r\n",
    "            })\n",
    "    return parallel_combinations\n",
    "\n",
    "def calculate_series_combinations(capacitors, max_series=5, max_capacitance=1000):\n",
    "    series_combinations = []\n",
    "    for r in range(1, min(max_series + 1, len(capacitors) + 1)):\n",
    "        for combination in combinations(capacitors, r):\n",
    "            equivalent_capacitance = sum(1 / cap['value'] for cap in combination) ** -1\n",
    "            if equivalent_capacitance > max_capacitance:\n",
    "                continue  # Discard this combination\n",
    "            total_volume = sum(cap['volume'] for cap in combination)\n",
    "            series_combinations.append({\n",
    "                'combination': \" + \".join(map(str, [cap['value'] for cap in combination])),\n",
    "                'equivalent_capacitance': equivalent_capacitance,\n",
    "                'total_volume': total_volume,\n",
    "                'count': r\n",
    "            })\n",
    "    return series_combinations\n",
    "\n",
    "def combine_files(file1_path, file2_path, output_file_path, max_capacitance=1000):\n",
    "    headers_file1, data_file1 = read_csv(file1_path)\n",
    "    headers_file2, data_file2 = read_csv(file2_path)\n",
    "\n",
    "    if headers_file1 != headers_file2:\n",
    "        raise ValueError(\"Headers in the two files are not the same.\")\n",
    "\n",
    "    combined_data = []\n",
    "\n",
    "    for row_file1 in data_file1:\n",
    "        for row_file2 in data_file2:\n",
    "            combination = f\"{row_file1[0]} and {row_file2[0]}\"\n",
    "            capacitance_sum = round(float(row_file1[1]) + float(row_file2[1]), 9)\n",
    "            total_volume_sum = round(float(row_file1[2]) + float(row_file2[2]), 9)\n",
    "\n",
    "            # Check total number of capacitors in the combination\n",
    "            count_file1 = row_file1[0].count('||') + row_file1[0].count('+') + 1\n",
    "            count_file2 = row_file2[0].count('||') + row_file2[0].count('+') + 1\n",
    "            if (count_file1 + count_file2) > 5:\n",
    "                continue  # Skip combinations with more than 5 capacitors\n",
    "\n",
    "            if capacitance_sum <= max_capacitance:\n",
    "                combined_data.append([combination, capacitance_sum, total_volume_sum])\n",
    "\n",
    "    write_csv(output_file_path, ['Combination', 'Cap(uF)', 'Total_Volume(mm^2)'], combined_data)\n",
    "\n",
    "def merge_all_files(output_file_path, *file_paths):\n",
    "    all_data = []\n",
    "    for file_path in file_paths:\n",
    "        headers, data = read_csv(file_path)\n",
    "        if not all_data:\n",
    "            all_data.append(headers)  # Add headers only once\n",
    "        all_data.extend(data)\n",
    "    \n",
    "    write_csv(output_file_path, all_data[0], all_data[1:])\n",
    "    print(f\"All data merged into {output_file_path}\")\n",
    "\n",
    "# Main code to generate parallel and series combinations and save to CSV\n",
    "\n",
    "capacitor_csv_filename = r'E:\\ai-power-converter-1\\new\\dataset\\calc\\cap.csv'\n",
    "output_parallel_csv = 'parallel_combinations_1.csv'\n",
    "output_series_csv = 'series_combinations_1.csv'\n",
    "combined_output_csv = 'combination_result_1.csv'\n",
    "final_merged_csv = 'merged_combinations_revisi.csv'\n",
    "\n",
    "# Read capacitor values and volumes from CSV\n",
    "capacitors = read_capacitor_values_from_csv(capacitor_csv_filename)\n",
    "\n",
    "# Calculate parallel combinations\n",
    "parallel_combinations = calculate_parallel_combinations(capacitors, max_capacitance=1000)\n",
    "\n",
    "# Save parallel combinations to CSV\n",
    "write_csv(output_parallel_csv, ['Combination', 'Cap(uF)', 'Total_Volume(mm^2)'], [\n",
    "    [comb['combination'], comb['equivalent_capacitance'], comb['total_volume']]\n",
    "    for comb in parallel_combinations\n",
    "])\n",
    "\n",
    "# Calculate series combinations\n",
    "series_combinations = calculate_series_combinations(capacitors, max_capacitance=1000)\n",
    "\n",
    "# Save series combinations to CSV\n",
    "write_csv(output_series_csv, ['Combination', 'Cap(uF)', 'Total_Volume(mm^2)'], [\n",
    "    [comb['combination'], comb['equivalent_capacitance'], comb['total_volume']]\n",
    "    for comb in series_combinations\n",
    "])\n",
    "\n",
    "# Combine both parallel and series combinations\n",
    "combine_files(output_parallel_csv, output_series_csv, combined_output_csv)\n",
    "\n",
    "# Merge all three CSV files into one\n",
    "merge_all_files(final_merged_csv, output_parallel_csv, output_series_csv, combined_output_csv)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
